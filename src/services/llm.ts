/**
 * LLM Service
 * Supports OpenAI and OpenRouter
 */

export type LLMProvider = 'openai' | 'openrouter';

export interface LLMConfig {
  provider: LLMProvider;
  apiKey: string;
  model: string;
  // GPT-5ä¸æ”¯æŒè¿™äº›å‚æ•°
  temperature?: number;
  maxTokens?: number;
}

export interface LLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export class LLMService {
  private config: LLMConfig | null = null;
  
  setConfig(config: LLMConfig): void {
    this.config = config;
  }
  
  async generateResponse(messages: LLMMessage[]): Promise<string> {
    if (!this.config) {
      throw new Error('LLMè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“');
    }
    
    const endpoint = this.getEndpoint();
    const headers = this.getHeaders();
    const body = this.buildRequestBody(messages);
    
    console.log('ğŸ¤– LLM ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:', {
      provider: this.config.provider,
      model: this.config.model,
      endpoint
    });
    
    try {
      const response = await fetch(endpoint, {
        method: 'POST',
        headers,
        body: JSON.stringify(body)
      });
      
      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.error?.message || `HTTP ${response.status}`);
      }
      
      const data = await response.json();
      const content = data.choices?.[0]?.message?.content;
      
      if (!content) {
        throw new Error('LLMå¿œç­”ãŒç©ºã§ã™');
      }
      
      console.log('âœ… LLM å¿œç­”å—ä¿¡:', content.substring(0, 100) + '...');
      return content;
    } catch (error) {
      console.error('âŒ LLM ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }
  
  async testConnection(): Promise<{ success: boolean; message: string; models?: string[] }> {
    if (!this.config) {
      return { success: false, message: 'LLMè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“' };
    }
    
    const startTime = Date.now();
    
    try {
      // ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
      await this.generateResponse([
        { role: 'system', content: 'ã‚ãªãŸã¯é¢æ¥ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚' },
        { role: 'user', content: 'ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚' }
      ]);
      
      const latency = Date.now() - startTime;
      
      return {
        success: true,
        message: `LLMæ¥ç¶šæˆåŠŸ (${latency}ms)`,
      };
    } catch (error) {
      return {
        success: false,
        message: error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼',
      };
    }
  }
  
  async getAvailableModels(): Promise<string[]> {
    if (!this.config) {
      throw new Error('LLMè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“');
    }
    
    try {
      const endpoint = this.config.provider === 'openai'
        ? 'https://api.openai.com/v1/models'
        : 'https://openrouter.ai/api/v1/models';
      
      const headers: Record<string, string> = {
        'Authorization': `Bearer ${this.config.apiKey}`,
        'Content-Type': 'application/json'
      };
      
      if (this.config.provider === 'openrouter') {
        headers['HTTP-Referer'] = window.location.origin;
        headers['X-Title'] = 'AI Interview Assistant';
      }
      
      const response = await fetch(endpoint, { headers });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      const data = await response.json();
      
      if (this.config.provider === 'openai') {
        // OpenAI: GPT-4ã¨GPT-5ãƒ¢ãƒ‡ãƒ«ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
        const models = data.data
          ?.map((m: any) => m.id)
          .filter((id: string) => 
            id.includes('gpt-4') || 
            id.includes('gpt-5') ||
            id.includes('gpt-3.5-turbo')
          ) || [];
        
        console.log('ğŸ“‹ OpenAIåˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:', models.length, 'å€‹');
        return models;
      } else {
        // OpenRouter: ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«
        const models = data.data?.map((m: any) => m.id) || [];
        console.log('ğŸ“‹ OpenRouteråˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:', models.length, 'å€‹');
        return models;
      }
    } catch (error) {
      console.error('âŒ ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  }
  
  private getEndpoint(): string {
    if (this.config!.provider === 'openai') {
      return 'https://api.openai.com/v1/chat/completions';
    } else {
      return 'https://openrouter.ai/api/v1/chat/completions';
    }
  }
  
  private getHeaders(): Record<string, string> {
    const headers: Record<string, string> = {
      'Authorization': `Bearer ${this.config!.apiKey}`,
      'Content-Type': 'application/json'
    };
    
    if (this.config!.provider === 'openrouter') {
      headers['HTTP-Referer'] = window.location.origin;
      headers['X-Title'] = 'AI Interview Assistant';
    }
    
    return headers;
  }
  
  private buildRequestBody(messages: LLMMessage[]): any {
    const body: any = {
      model: this.config!.model,
      messages: messages
    };
    
    // GPT-5ã¯ temperature, max_tokens ãªã©ã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„
    const isGPT5 = this.config!.model.includes('gpt-5');
    
    if (!isGPT5) {
      if (this.config!.temperature !== undefined) {
        body.temperature = this.config!.temperature;
      }
      if (this.config!.maxTokens !== undefined) {
        body.max_tokens = this.config!.maxTokens;
      }
    }
    
    return body;
  }
}

export const llmService = new LLMService();

